---
sidebar_position: 7
---

# 5. Assess model

## 5.3 Document model evaluation metrics
**Model developer**: Document all fit statistics used for model evaluation.
Document resulting values for the champion and challenger models.

## 5.4 Assess model bias

### 5.4.1 Model needs bias evaluation?
**Model developer**: Does the model require bias evaluation, based on the implications for the use of the AI system, among other factors?

Does the model require bias evaluation, based on use case and affected population?

* [ ] Yes
* [ ] No

Please justify your response.

### 5.4.2 Compare subgroup model performance
**Model developer**: Calculate and compare model performance values and additional fairness metrics for each protected class or subgroup.
To calculate model performance values, use model performance metrics defined by your organization in the testing strategy outlined in step
`3.1.5 - Document performance metrics`.
Fairness metrics might include equal opportunity, demographic parity, predictive parity, equal accuracy, or equalized odds. Subgroups are often protected classes.
However, they could be important groups within the data based on the model use case, even though they are not legally defined as protected classes.

### 5.4.3 Document subgroup model performance
**Model developer**: Document subgroup model performance and fairness metric values for each protected class or subgroup found in step `5.3.2 - Compare subgroup model performance`.

### 5.4.4 Compare average model predictions per subgroup
**Model developer**: Calculate and compare average model predictions for each protected class or subgroup.
Protected classes are groups of people who are legally protected from discrimination based on a shared characteristic, like disability, sexual orientation, or race.
Subgroups are often protected classes.
However, they could be important groups within the data based on the model use case, even though they are not legally defined as protected classes.

### 5.4.5 Document average model predictions per subgroup
**Model developer**: Document average model predictions for each protected class or subgroup found in step `5.3.4 - Compare average model predictions per subgroup`.

### 5.4.6 Bias metrics differences satisfactory?
**Model owner**: If bias evaluation is required, document why the differences in bias metric values are satisfactory.

Are the differences in bias metric values satisfactory?

* [ ] Yes
* [ ] No

Please justify your response.

### 5.4.7 Bias metrics differences unsatisfactory. What next?
**Model owner**: Bias metrics are outside of established thresholds.
Decide what should be done next.

How should bias be mitigated?

* [ ] Retrain models
* [ ] End the workflow
* [ ] Modify or update data
* [ ] Move forward with the model

### 5.4.8 Justify moving forward
**Model owner**: If bias evaluation is required and bias metrics were outside of established thresholds but you are continuing to use the model, provide justification for moving forward with the model.

### 5.4.9 Modify or update data
**Data engineer**: If you decided to modify or update the data based on bias evaluation results, retrain the model with the updated data and ensure that the new model generates bias metrics that are within the established thresholds.
Document results in the Assess Model Bias tasks.

### 5.4.10 Retrain models
**Model developer**: If you chose to retrain your model, retrain models to identify a model that will pass according to the testing strategy.
If you decided to retrain the model using modified settings, ensure that the new model generates bias metrics that are within the established thresholds.
Document results in the Assess Model Bias tasks.

## 5.5 Assess model explainability

### 5.5.1 Is model explainability important?
**Model developer**: Is model explainability or interpretability important for this use case?
An explainable model allows human users to comprehend and trust the results of the output generated by the model.
Explainability is important in most use cases.

Is explainability important for this use case?

* [ ] Yes
* [ ] No

Please justify your response.

### 5.5.2 Document model explainability
**Model developer**: Document model explainability method and results.
Ensure that explainability information is made available to the model end user.
Select the most appropriate explainability methods for the use case and model type.
SAS Viya includes explainability tools such as Partial Dependence (PD) plots, Individual Conditional Expectation (ICE) plots, Local Interpretable Model-Agnostic Explanation (LIME), and Kernel Shapley values (Kernel SHAP).
These techniques are model-agnostic, which means that these techniques can be applied to any model that is generated by a supervised learning node.

### 5.5.3 Model explanations satisfactory?
**Model owner**: Indicate whether model explanations are satisfactory.
Describe the model's level of explainability and justify why explanations are acceptable.

Are model explanations satisfactory?

* [ ] Yes
* [ ] No

Please justify your response.
